#!/usr/bin/env python3
"""
æ‰‹åŠ¨ä¸‹è½½ RAG Embedding æ¨¡å‹çš„è„šæœ¬

ä½¿ç”¨æ–¹æ³•:
    python scripts/download_rag_model.py

æˆ–è€…æŒ‡å®šç¼“å­˜ç›®å½•:
    python scripts/download_rag_model.py --cache-dir /path/to/cache
"""

import argparse
import sys
from pathlib import Path

try:
    from huggingface_hub import snapshot_download
except ImportError:
    print("é”™è¯¯: éœ€è¦å®‰è£… huggingface_hub")
    print("è¯·è¿è¡Œ: pip install huggingface_hub")
    sys.exit(1)


def download_model(cache_dir: Path = None):
    """ä¸‹è½½ RAG embedding æ¨¡å‹"""

    # ç¡®å®šç¼“å­˜ç›®å½•
    if cache_dir is None:
        # å°è¯•ä½¿ç”¨é¡¹ç›®é…ç½®
        try:
            from app.core.config import settings

            if hasattr(settings, "static_root"):
                cache_dir = settings.static_root / "hf_cache"
            else:
                cache_dir = Path.home() / ".cache" / "huggingface"
        except Exception:
            cache_dir = Path.home() / ".cache" / "huggingface"

    cache_dir = Path(cache_dir)
    cache_dir.mkdir(parents=True, exist_ok=True)

    # è®¾ç½®ç¯å¢ƒå˜é‡
    import os

    os.environ["HF_HUB_CACHE"] = str(cache_dir.absolute())

    # æ¨¡å‹ä¿¡æ¯
    model_id = "sentence-transformers/all-MiniLM-L6-v2"
    model_dir = cache_dir / "hub" / f"models--{model_id.replace('/', '--')}"

    print("=" * 60)
    print("RAG Embedding æ¨¡å‹ä¸‹è½½å·¥å…·")
    print("=" * 60)
    print(f"æ¨¡å‹: {model_id}")
    print(f"ç¼“å­˜ç›®å½•: {cache_dir.absolute()}")
    print(f"æ¨¡å‹ç›®å½•: {model_dir.absolute()}")
    print("=" * 60)
    print()

    # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
    if model_dir.exists() and any(model_dir.iterdir()):
        print(f"âš ï¸  æ¨¡å‹ç›®å½•å·²å­˜åœ¨: {model_dir}")
        response = input("æ˜¯å¦é‡æ–°ä¸‹è½½? (y/N): ").strip().lower()
        if response != "y":
            print("å–æ¶ˆä¸‹è½½")
            return

    try:
        print(f"ğŸ“¥ å¼€å§‹ä¸‹è½½æ¨¡å‹: {model_id}")
        print("   è¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼Œè¯·è€å¿ƒç­‰å¾…...")
        print()

        snapshot_download(
            repo_id=model_id,
            local_dir=model_dir,
            local_dir_use_symlinks=False,
            resume_download=True,  # æ”¯æŒæ–­ç‚¹ç»­ä¼ 
        )

        print()
        print("âœ… ä¸‹è½½å®Œæˆ!")
        print(f"   æ¨¡å‹ä½ç½®: {model_dir.absolute()}")
        print()
        print("ç°åœ¨å¯ä»¥å¯åŠ¨åº”ç”¨ï¼ŒRAG ç³»ç»Ÿå°†è‡ªåŠ¨ä½¿ç”¨æ­¤æ¨¡å‹ã€‚")

    except Exception as e:
        print()
        print(f"âŒ ä¸‹è½½å¤±è´¥: {e}")
        print()
        print("å¯èƒ½çš„è§£å†³æ–¹æ¡ˆ:")
        print("1. æ£€æŸ¥ç½‘ç»œè¿æ¥")
        print("2. ä½¿ç”¨ä»£ç†:")
        print("   export HTTP_PROXY=http://your-proxy:port")
        print("   export HTTPS_PROXY=http://your-proxy:port")
        print("3. ä½¿ç”¨é•œåƒç«™ç‚¹ (å¦‚æœåœ¨ä¸­å›½):")
        print("   export HF_ENDPOINT=https://hf-mirror.com")
        print("4. æ‰‹åŠ¨ä¸‹è½½: å‚è€ƒ docs/manual_model_download.md")
        sys.exit(1)


def main():
    parser = argparse.ArgumentParser(description="ä¸‹è½½ RAG Embedding æ¨¡å‹")
    parser.add_argument(
        "--cache-dir",
        type=str,
        help="æŒ‡å®šç¼“å­˜ç›®å½•è·¯å¾„",
    )

    args = parser.parse_args()

    cache_dir = Path(args.cache_dir) if args.cache_dir else None
    download_model(cache_dir)


if __name__ == "__main__":
    main()
